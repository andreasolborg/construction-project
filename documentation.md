# Required packages and software:
- sklearn 
- numpy
- panda
- seaborn
- matplotlib
- openpyxl

# General overview:
## Classes:
### Task: 		    
This class represents a task in a project. Every task has attributes for ES, EF, LS, and LF that are initially set to None until we run the algorithms for finding early and late dates in the Project class. Every task has list attributes for predecessors and successors so every task in a project is binded togheter like a linked list. Each task has a triangularly distributed duration range that incorporates a risk factor specific to the task. The actual duration for a task is selected randomly from this distribution. A task also has som general attributes as code, type and description.
### Project: 		    
For encoding PERT diagrams, we created a Task class which serves as Node objects in the PERT-diagram. The Project class has functions for determining shortest, expected, and longest duration of a project. This is done by calling the find_early_dates function that takes in the parameter duration_index, which follows the algorithm described in the assignment description. If a duration_index is set to n, it will choose the n-th duration in duration range, so zero index will set all tasks to their shortest duration, and 2 will set all tasks to their longest duration. If no duration_index is set, it will randomly choose a duration between (min, mode, max) using the triangular distribution with the risk factor taken into account. After iterating over all tasks, the find_early_dates function will then set the projects duration to the maximum of all the tasks early completion dates. The Project class also has a loader for Excel spreadsheets for importing projects. This is done by calling the import_project_from_excel function. This function will iterate over all the rows in the Excel spreadsheet and create a Task object for each row. It will then add the predecessors and successors to each Task object, and add the Task object to the projects list of tasks. The Project class also has a printer function that prints sufficient information about each task in the project. Running this function with the Warehouse project gives output that matches the output in the assignment description. 
### Utils: 	        
The Utils class, provides utility functions that are not directly tied to any specific class but are useful for general operations in the project. The Utils class includes four methods: make_samples, make_mixed_samples_of_random_risk_factors, write_to_csv, and perform_statistics. The function make_samples makes at sample of n random values of durations for each value of the risk factor. This function also takes in arguments for placing a gate, but will not place a gate if the arguments is not set. The function make_mixed_samples_of_random_risk_factors is used to make samples with random risk factors instead of making n samples for each risk factor like the make_samples function. This cuts down on the amount of samples needed to be made, and computing time. The function also takes in arguments for placing a gate like the make_samples function. The function write_to_csv takes in a list of samples, and writes the data to a specified CSV file. This CSV file is intended to be used as input for machine learning algorithms. The perform_statistics function calculates and displays various statistical measures for the durations and classifications of the given samples, grouped by risk factors. The function accepts a dictionary where the keys represent different risk factors and the corresponding values are lists containing the associated samples for each risk factor. The displayed statistics include minimum, maximum, mean, standard deviation, deciles for durations, and the number of successful, acceptable, and failed projects.

### MachineLearning:	
The MachineLearning class is designed to perform machine learning tasks on a given CSV file. It contains two main functions: run_classification_methods and run_regression_methods. The function run_classification_methods applies classification algorithms (Logistic Regression, Random Forest, Support Vector Machine, and Decision Tree) on the dataset. It first reads the CSV file, splits the data into features and labels, and then into training and test sets. Afterward, it trains the models, evaluates their performance, and generates confusion matrices to visualize the results. The function run_regression_methods performs regression analysis on the dataset using Linear Regression, Random Forest, Support Vector Machine, and Decision Tree algorithms. Similar to the classification function, it reads the CSV file, splits the data, and trains the models. It then evaluates the models' performance using the metrics R-squared, mean squared error and absolute squared, and calculates the accuracy score.
### Main: 	        
This script runs all the tasks in the assignment, including tasks 1 through 6.

